# -*- coding: utf-8 -*-
"""UNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NVRU781HGndQ6-qIkgm4mdtCd38VpRGq
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms.functional as TF
import torch.nn.init as init
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt

from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Dataset, random_split
from tqdm import tqdm

"""# U-Net Model"""

class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False), # bias = False because of batchnorm
            nn.BatchNorm2d(out_channels), # batch norm is founded after U-Net, but it's beneficial
            nn.ReLU(inplace=True),

            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.conv(x)

class UNet(nn.Module):
      def __init__(
          self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]
          ):
        super().__init__()
        self.downs = nn.ModuleList()
        self.ups = nn.ModuleList()
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

        # Down part
        for feature in features:
            self.downs.append(DoubleConv(in_channels, feature))
            in_channels = feature

        # Up part
        # có thể dùng bilinear -> conv layer cho upsampling
        # ở đây dùng transposed convolution (vì GAN dùng transposed convolutions create artifacts (?))
        for feature in reversed(features):
            self.ups.append(
                nn.ConvTranspose2d(
                    feature*2, feature, kernel_size=2, stride=2
                ) # skip connection
            )
            self.ups.append(DoubleConv(feature*2, feature))

        self.bottleneck = DoubleConv(features[-1], features[-1]*2)

        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)

      def forward(self, x):
        skip_connections = []

        for down in self.downs:
            x = down(x)
            skip_connections.append(x)
            x = self.pool(x)

        x = self.bottleneck(x)
        skip_connections = skip_connections[::-1]

        for idx in range(0, len(self.ups), 2):
            x = self.ups[idx](x) # vì ups là đi theo cặp upconv - doubleconv
            skip_connection = skip_connections[idx//2]
            if x.shape != skip_connection.shape: # có thể cropping, add paddings
                x = TF.resize(x, size=skip_connection.shape[2:])
            concat_skip = torch.cat((skip_connection, x), dim=1)
            x = self.ups[idx+1](concat_skip)

        x = self.final_conv(x)

        return x